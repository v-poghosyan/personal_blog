[
  {
    "objectID": "posts/python/setting_up_your_ML_environment.html",
    "href": "posts/python/setting_up_your_ML_environment.html",
    "title": "Setting Up Your Local Development Environment for Machine Learning",
    "section": "",
    "text": "In this post we’ll be going over how to set up your local development environment for developing machine learning applications, and for blogging with Jupyter Notebooks."
  },
  {
    "objectID": "posts/python/setting_up_your_ML_environment.html#installing-python-on-the-system-level-optional",
    "href": "posts/python/setting_up_your_ML_environment.html#installing-python-on-the-system-level-optional",
    "title": "Setting Up Your Local Development Environment for Machine Learning",
    "section": "Installing Python on the System Level (Optional)",
    "text": "Installing Python on the System Level (Optional)\nFirst, we download and install the latest version of Python for our OS from the official website.\n\n\n\n\n\n\nAdd to PATH\n\n\n\n\n\nMake sure to tick the “add to PATH” box during the installation so that the path of the Python executible is added to our system’s PATH environment variable. The path in question, by default, is ~\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n\n\n\n\n\n\n\n\n\nIf the command python is unrecognized on Windows…\n\n\n\n\n\nOn Windows, we should be able to now use the command py to invoke the Python interpreter. Running py --version should return the version number. As of the time of writing this, the output is Python 3.11.5"
  },
  {
    "objectID": "posts/python/setting_up_your_ML_environment.html#installing-anaconda-navigator-or-miniconda",
    "href": "posts/python/setting_up_your_ML_environment.html#installing-anaconda-navigator-or-miniconda",
    "title": "Setting Up Your Local Development Environment for Machine Learning",
    "section": "Installing Anaconda Navigator (or Miniconda)",
    "text": "Installing Anaconda Navigator (or Miniconda)\nNext, download and install Anaconda Navigator (or Miniconda, which installs the Conda scientific package and Python environment manager without additional software and without the GUI navigator). This installation includes tools like Jupyter Notebooks, Spyder, PyCharm, and other scientific packages and IDEs.\n\n\n\n\n\n\nAnaconda’s built in Python distribution…\n\n\n\n\n\nAnaconda comes with its own latest Python version distribution (by default installed into path c:\\ProgramData\\anaconda3\\python.exe). The installer will prompt us to select an option which enables third-party editors, such as VSCode, to recognize this Python distribution.\n\n\n\n\n\n\n\n\n\nDifferent Python distributions on the same machine\n\n\n\n\n\nRunning python --version in the Anaconda Prompt returns Python 3.11.4 as of the time of writing this, which is the version of Python that Conda installed in its base environment. Crucially, running py --version, even in the Anaconda Prompt, still returns Python 3.11.5, which is the system’s version of Python."
  },
  {
    "objectID": "posts/python/setting_up_your_ML_environment.html#choosing-the-right-python-kernel-in-vscode",
    "href": "posts/python/setting_up_your_ML_environment.html#choosing-the-right-python-kernel-in-vscode",
    "title": "Setting Up Your Local Development Environment for Machine Learning",
    "section": "Choosing the Right Python Kernel in VSCode",
    "text": "Choosing the Right Python Kernel in VSCode\nIn VSCode, we can open the Command Palette and run the command Notebook: Select Notebook Kernel. At first, this will prompt us to install the Jupyter and Python VSCode extensions. Once that’s done, we can rerun the command and select the Python kernel in the desired Conda environment (by default base)."
  },
  {
    "objectID": "posts/python/setting_up_your_ML_environment.html#initializing-conda-in-the-shell",
    "href": "posts/python/setting_up_your_ML_environment.html#initializing-conda-in-the-shell",
    "title": "Setting Up Your Local Development Environment for Machine Learning",
    "section": "Initializing Conda in the Shell",
    "text": "Initializing Conda in the Shell\nBefore we can use the full capabilities of Conda in the terminal, we need to initialize it by running the command:\nconda init &lt;bash|powershell|tsh|...&gt; # Depending on the shell we're using\nRestart your terminal for changes to take hold.\n\n\n\n\n\n\nFor Windows users, Powershell may throw the following error trying to load the user profile after a restart: execution of scripts is disabled on this system. This is Powershell’s security measure against command hijacking, and its way of enforcing control of execution and establishing identity. If this is the case, run cmd.exe as Administrator and execute command powershell Set-ExecutionPolicy RemoteSigned -Scope CurrentUser. We should now see the active environment in parentheses (e.g. base) to the left of the input in Powershell"
  },
  {
    "objectID": "posts/python/setting_up_your_ML_environment.html#conda-commands",
    "href": "posts/python/setting_up_your_ML_environment.html#conda-commands",
    "title": "Setting Up Your Local Development Environment for Machine Learning",
    "section": "Conda Commands",
    "text": "Conda Commands\nSome common Conda commands are:\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\nconda env list\nShows all the Conda environments (the active environment is marked with *)\n\n\nconda list\nShows all ther packages installed in the currently active environment\n\n\nconda update --all\nUpdates all packages in the active environment (frequently resolves environment is inconsistent errors)\n\n\nconda info\nShows, among other things, the directory where the environment is stored\n\n\nconda activate &lt;myenv&gt;\nActivate environment &lt;myenv&gt;\n\n\nconda deactivate\nDeactivates the currently active environment\n\n\nconda create --name &lt;myenv&gt;\nCreate a new empty environment\n\n\nconda create --name &lt;myenv&gt; --clone base\nClone the base environment\n\n\nconda env export -f &lt;path/to/envfile.yml&gt;\nExport the package list of the active environment (e.g. conda env export -f  /Users/&lt;username&gt;/Documents/MyFiles/personal-blog.yml)\n\n\nconda compare &lt;path/to/envfile.yml&gt;\nCompare the active environment to the exported file of another environment\n\n\nconda remove --name &lt;myenv&gt; --all\nDeletes the environment\n\n\n\n\nComparing Conda Environments\nOften we need to compare the packages between two environments. Here’s the workflow to do that:\n\nActivate one of the environments\nExport its package list as .yml to a destination of our choice\nActivate the second environment\nExecute the compare command, providing the path to the .yml file created in step 3"
  },
  {
    "objectID": "posts/python/setting_up_your_ML_environment.html#pythons-built-in-data-types",
    "href": "posts/python/setting_up_your_ML_environment.html#pythons-built-in-data-types",
    "title": "Setting Up Your Local Development Environment for Machine Learning",
    "section": "Python’s Built-In Data Types",
    "text": "Python’s Built-In Data Types\n\nArrays\nA 1D array, or a vector, is a collection of scalars (usually, but not necessarily, of similar data type) in a contiguous chunk of computer memory. A 2D array, or a matrix, is a collection of vectors. A 3D array (or a higher dimensional array), also referred to as a tensor, is a collection of matrices."
  },
  {
    "objectID": "posts/python/setting_up_your_ML_environment.html#numpy-data-types",
    "href": "posts/python/setting_up_your_ML_environment.html#numpy-data-types",
    "title": "Setting Up Your Local Development Environment for Machine Learning",
    "section": "NumPy Data Types",
    "text": "NumPy Data Types\nNumPy exposes the ndarray type. This is a multidimensional, homogeneous array type (i.e. its elements are of the same data type) optimized for computing and indexed by a tuple. It offeres mathematical indexing (based on Boolean expressions) so that we don’t have to write inefficient loops. The terms vector, matrix, and tensor equally apply to ndarrays.\nTo import NumPy, we can type:\n\nimport numpy as np\n\n\nWorking with ndarrays\n\nCreating ndarrays (arange, zero, one)\n\nsequence_array = np.arange(10)\nprint(sequence_array)\n\n[0 1 2 3 4 5 6 7 8 9]\n\n\n\nzeros_array = np.zeros((3,4),dtype='int32')\nprint(zeros_array)\nprint(zeros_array.dtype)\n\n[[0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]]\nint32\n\n\n\nones_array = np.ones((3,2))\nprint(ones_array)\nprint(ones_array.dtype)\n\n[[1. 1.]\n [1. 1.]\n [1. 1.]]\nfloat64\n\n\n\n\nVerifying Type\nWe can verify that the object we’re working with is, indeed, and ndarray by using the built-in Python type function.\n\narray1 = np.array([1,2,3])\nprint('array1 type: ', type(array1))\n\narray1 type:  &lt;class 'numpy.ndarray'&gt;\n\n\n\n\nGetting the Shape\nThe shape of an ndarray is in format (x,y,...) where x corresponds to the number rows, y corresponds to the number of columns, and so on.\n\nprint('array1 shape: ', array1.shape)\n\narray1 shape:  (3,)\n\n\nHigher dimensional ndarrays take tuples of arrays as input:\n\nContrived Example of a Multidimensional ndarray\nThere is a subtle difference between a 1D array and a 2D array with a single column which is worth exploring.\nAs we saw above, array1 was of shape (3,). Now let’s examine the shape of a similar ndarray instance.\n\narray2 = np.array([[1],[2],[3]])\nprint('array2 shape: ', array2.shape)\n\narray2 shape:  (3, 1)\n\n\nAs we can see, this one’s shape is (3,1).\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe shape (3,) means a 1D array with 3 elements, meanwhile the shape (3,1) means a 2D array with 3 rows and a single column.\n\n\n\nSometimes these differences are just superficial, or the result of data impurities. NumPy provides a method called np.squeeze which flattens the arrays by removing axes of length 1.\n\nprint(np.squeeze(array2).shape == array1.shape)\n\nTrue\n\n\n\n\nA More Natural Example of a Multidimensional ndarray\n\narray3 = np.array([[1,2,3], \n                  [4,5,6]])\nprint('array3 shape: ', array3.shape)\n\narray3 shape:  (2, 3)\n\n\n\n\n\nGetting the Dimension\nTo get the dimension, we use ndarray.ndim.\n\nprint(array1.ndim, array2.ndim, array3.ndim)\n\n1 2 2\n\n\n\n\nGetting the Data Types of The Elements\nndarrays can include numeric types (int, unsigned int, float, complex), text types (string), and null. However, as mentioned above, ndarrays can’t include more than one data type. To get the data type of the elements, we use ndarray.dtype.\n\nprint(array1.dtype)\n\nint32\n\n\n\n\nReshape\nWe can reshape ndarrays where it makes sense. For example, we can reshape array3, of shape (2,3) into an array of shape (3,2), (6,1), or (1,6).\n\nprint(array3)\nprint(array3.shape)\narray4 = array3.reshape(3,2)\nprint(array4)\nprint(array4.shape)\n\n[[1 2 3]\n [4 5 6]]\n(2, 3)\n[[1 2]\n [3 4]\n [5 6]]\n(3, 2)\n\n\nProviding the value -1 for either row or column makes the reshape automatic across that dimension. For instance, instead of array3.reshape(3,2) we could say array3.reshape(-1,2) or array3.reshape(3,-1). This would achieve the same effect."
  },
  {
    "objectID": "posts/linear_algebra/linalg_intro_to_linear_algebra.html",
    "href": "posts/linear_algebra/linalg_intro_to_linear_algebra.html",
    "title": "Review of Linear Algebra and Geometry for ML",
    "section": "",
    "text": "We start our exploration of mathematics for machine learning with a refresher on convexity and, in general, the linear algebra that’s commonly used in the subject.\n\n\nSet convexity is defined as follows:\n\nDefinition:   A set \\(C \\subseteq \\mathbb{R^d}\\) is convex if, for all points \\(x_1,x_2 \\in C\\) and any \\(\\theta \\in [0,1]\\), the point \\(\\theta x_1 + (1-\\theta) x_2\\)\n\nThat is, a set is convex if the parametrized line segment between \\(x_1\\) and \\(x_2\\), any two points in the set, is also entirely within the set. \n\n\nScaling, skewing, and rotation (i.e. linear transformations) preserve convexity, as do affine transformations (i.e. shifting). Let the matrix \\(A\\) define such a transformation, and \\(b\\) be a shift vector. Then \\(C' = \\{Ax + b : x \\in C \\}\\) is convex provided that \\(C\\) was convex.\nAn intersection of convex sets is also convex. That is, \\(C' = \\{ x : x \\in C_1 \\cap x \\in C_2 \\}\\) is convex provided that \\(C_1\\) and \\(C_2\\) were convex to begin with. The proof follows directly from the definition of intersection.\nHowever, unions of convex sets need not be convex.\n\n\n\n\nThe following are some common convex sets we will come across in practice. To discuss sets, we should build up from points. For the purposes of the discussion that follows, A point and a vector mean the same thing.\n\n\nA convex combination of points \\(x_1, ..., x_n\\) is a point of the form \\(x = \\theta_1 x_1 + ... + \\theta_n x_n\\) where \\(\\sum_{i = 1}^{n} \\theta_i = 1\\) and \\(\\theta_i \\geq 0 \\ \\ \\forall i\\).\nLet \\(x_1,x_2,...,x_n\\) be \\(n\\) points in space. Their convex hull is the set of all points which can be written as some convex combination of them. Equivalently, by varying the \\(\\theta_i\\)’s we generate the convex hull as the set of all convex combinations of these points.\nThe convex hull can be visualized as the closed polygon formed when a rubber band is stretched around the \\(n\\) points. The convex hull of two points is the line segment joining them. That of three points is the polygon (complete with its inner region). In general, for \\(n\\) points, the concept generalizes to an \\(n\\)-dimensional polygon.\nFormally, the convex hull is the set \\(\\{ \\theta_1 x_1 + ... + \\theta_n x_n : \\theta_1 + ... + \\theta_n = 1 \\ \\ \\textrm{and} \\ \\ \\theta_i \\geq 0 \\ \\ \\forall i \\}\\)\n\n\n\n\n\n\nNote\n\n\n\n\n\nA handy interactive visualization, along with an efficient algorithm that generates a convex hull of \\(n\\) points on a 2D plane can be found in the following blog post by Joel Gibson.\n\n\n\n\n\n\nThe convex hull of a set can be similarly defined as all the convex combinations of the elements in the set. However, since the set may contain infinite elements there’s an easier, equivalent definition in terms of supersets.\nLet \\(C\\) be a non-convex set. The convex hull of \\(C\\) is the intersection of all convex supersets of \\(C\\). That is, it’s the intersection of all convex sets containing \\(C\\). The result of such an intersection will be the unique \\(^{(†)}\\) smallest convex superset of \\(C\\), its convex hull.\n\n\n(†) Proof of uniqueness: Let \\(C_1\\) and \\(C_2\\) be two convex hulls of \\(C\\). Let \\(c_1 \\in C_1\\) be a point. Since \\(c_1 \\in C_1\\), \\(c_1 \\in\\) at least one of the convex supersets \\(C^{i}\\)of \\(C\\). Hence, \\(c_1 \\in C_2\\) since \\(C_2 = \\bigcap^{i=1 \\to n}C^{i}\\). Similarly, it can be shown that any \\(c_2 \\in C_2\\) also belongs to \\(C_1\\). Hence, \\(C_1 \\subseteq C_2\\) and vice versa. This proves that \\(C_1 = C_2\\) and completes the proof of uniqueness.\nVisualizing the convex hull of a non-convex set is similar to visualizing that of \\(n\\) points — it’s simply the shape enclosed by a rubber band stretched around the non-convex set.\n\n\n\nAn affine combination of points \\(x_1,...,x_n\\) is a point of the form \\(x = \\theta_1 x_1 + ... + \\theta_n x_n\\) with \\(\\sum_{i=1}^{n}\\theta_i = 1\\) but where the \\(\\theta_i\\)’s need not be non-negative.\nFor a single point, the set of all affine combinations is the singleton set with the point itself. For two points, it’s the line that passes through them, and for three points it’s the plane. In general, it is the plane in \\(n\\)-dimensions passing through the \\(n\\) points.\n\n\n\nA linear combination of \\(n\\) vectors, on the other hand, is all vectors of the form \\(x = \\theta_1 x_1 + ... + \\theta_n x_n\\) with the \\(\\theta_i\\)’s totally unrestricted.\nThe set of all linear combinations of \\(n\\) points is called their span. Formally, it is the set \\(\\{ \\theta_1 x_1 + ... + \\theta_n x_n : \\forall \\theta_1,...,\\theta_n \\}\\).\nThe span of a single point is the line passing through it. For two vectors the span is the plane passing through them and, in general, the span of \\(n\\) points is a plane in \\((n+1)\\)-dimensions which contains these points.\n\n\nFor fixed weights \\(\\theta_i = a_i \\ \\ \\forall i\\), a hyperplane is the set of all points \\(x \\in \\mathbb{R^n}\\) whose linear combination equals a fixed constant \\(b \\in \\mathbb{R}\\).\nFormally, a hyperplane is the set \\(\\{ x : a_1 x_1 + ... a_n x_n = b\\} = \\{ x : a^T x = b\\}\\)\nThere’s a geometric interpretation of the parameters \\(a \\in \\mathbb{R^n}\\) and \\(b \\in \\mathbb{R}\\). Since the dot-product between perpendicular vectors is \\(0\\), \\(\\{ x : a^T x = 0\\}\\) is simply the set of all vectors perpendicular to \\(a\\) (whose tail, as with all vectors in linear algebra, is considered to be fixed at the origin), making \\(a\\) the normal vector to the hyperplane passing through the origin. To allow for parallel hyperplanes that are translated from the origin, the offset \\(b \\in \\mathbb{R}\\) is introduced in the generalization \\(\\{ x : a^T x = b \\}\\). This is now the set of all vectors whose dot-product with \\(a\\) is constant. These vectors are not quite perpendicular to \\(a\\), but they form a parallel hyperplane that’s been shifted from the origin by a distance of \\(\\frac{|b|}{\\|a\\|_2}\\).\nSince the sum \\(a_1 x_1 + ... a_n x_n = b\\) is fixed, the last coordinate, which we’ll call \\(x_k\\) for some \\(k \\in [1,...,n]\\), is fixed by the choice of the other \\(n-1\\) coordinates. Therefore, a hyperplane in \\(\\mathbb{R^n}\\) spans \\(n-1\\) dimensions instead of \\(n\\). \n\n\n\nA halfspace is either of the two sub-spaces a hyperplane partitions the whole space into. Since the dot-product between vectors which are roughly in the same direction is positive, and vice versa, the two halfspaces associated to a hyperplane \\(\\{ x : a^T x = b\\}\\) are \\(\\{ x : a^T x \\geq b\\}\\) and \\(\\{ x : a^T x \\leq b\\}\\).\n\n\n\n\nA conic combination of \\(x_1,...x_n\\) is a point \\(x = \\sum_{i=1}^{n} \\theta_i x_i\\) where \\(\\theta_i \\geq 0 \\ \\ \\forall i\\). Note that the absence of the restriction that \\(\\sum_{i=1}^{n} \\theta_i = 1\\) is what distinguishes a conic combination from a convex combination.\n\n\n\nRecall from Euclidean geometry that ellipses are conic sections. In general we define ellipses in \\(n\\)-dimensions as the sub-level sets of quadratic forms. That is \\(\\{ x : (x-c)^T M (x-c) \\leq 1 \\}\\) where \\(M \\succeq 0\\) defines the stretch along each principal axis, and \\(c \\in \\mathbb{R^n}\\) is the center.\nAn equivalent definition of an ellipse using the L2-norm is \\(\\{ x : \\|Ax - b\\|_2 \\leq 1 \\}\\). That is, for a given \\(A\\) and \\(b\\) in the L2-norm definition, we can find an \\(M\\) and \\(c\\) in the sub-level set definition and vice versa.\n\n\n\n\n\n\nNote\n\n\n\n\n\nMore generally, the ellipse is \\(\\{ x : (x-c)^T M (x-c) \\leq r \\}\\). However, since the scaling factor \\(r\\) is positive, it can simply be absorbed into \\(Q\\) without affecting \\(Q\\)’s positive semidefiniteness.\n\n\n\nTo quickly convince ourselves in the equivalence of these definitions, we take the simple case where \\(b = 0\\).\n\\[\n\\begin{aligned}\n  \\|Ax\\|_2 &= ((Ax)^T(Ax))^{1/2} \\\\\n  &= (x^TA^TAx)^{1/2} \\\\\n  &= (x^TU D U^Tx)^{1/2} \\\\\n  &= x^TU D^{1/2} U^Tx \\\\\n  \\end{aligned}\n\\]\nWhere the third equality is by the spectral decomposition of the real symmetric matrix \\(A^TA\\), in which \\(D = diag(\\lambda_1,...,\\lambda_n)\\) is the diagnonal matrix of eigenvalues and the columns of \\(U\\) are the corresponding eigenvectors. Taking \\(M= UD^{1/2}U^T\\), where \\(D^{1/2}\\) is simply \\(D^{1/2} = diag(\\sqrt\\lambda_1,...,\\sqrt\\lambda_n)\\), we have the equivalent sub-level set definition of the ellipse.\n\n\n\nRelated to ellipses are Euclidean balls, which are norm balls for the choice of the L2-norm. A Euclidean ball has the form \\(\\{ x : \\|x\\|_2 \\leq r \\}\\), and is clearly convex as it’s a generalizations of the sphere in \\(n\\)-dimensions.\nBut also, a Euclidean ball is the special ellipse for the choice of \\(M = rI\\), and \\(c = 0\\).\nIn general, norm balls \\(\\{ x : \\|x\\|_p \\leq r\\}\\) where \\(\\|x\\|_p = (x_1^p + ... + x_n^p)^{1/p}\\) are convex for any choice of \\(p \\geq 1\\).\n\n\n\nWhere a halfspace is a set with one linear inequality constraint, a polyhedron is a set with many, but finite, such linear inequality constraints. These constraints can be packed into a matrix \\(A \\in \\mathbb{R^{m \\times n}}\\) by vector \\(b \\in \\mathbb{R^m}\\) multiplication form, making the polyhedron into the set \\(\\{x : Ax \\leq b\\}\\).\nSince polyhedra are simply intersections of halfspaces and hyperplanes, and the latter are both convex, polyhedra are also convex sets.\n\n\n\nThe set of all PSD matrices \\(\\{ Q : x^TQx \\geq 0, \\ \\ \\forall x \\in \\mathbb{R^m}\\}\\) is convex. We can, of course, use the definition of convexity to show this. But, a more elucidative approach would be the following remark.\nNote that \\(Q \\mapsto x^TQx\\) is a linear functional that maps the space of all PSD matrices to its field of scalars. This is analogous to how \\(a \\mapsto x^Ta\\) is a linear functional so, just as \\(\\{ a : x^Ta \\geq 0 \\}\\) is a halfspace in the space of vectors, \\(H_x = \\{ Q : x^TQx \\geq 0 \\}\\) for a given choice of \\(x \\in \\mathbb{R^m}\\) is a halfspace in the space of PSD matrices. Halfspaces, as we already know, are convex and \\(\\{ Q : x^TQx \\geq 0, \\forall x \\in \\mathbb{R^m}\\}\\) is nothing but an intersection of halfspaces for each choice of \\(x\\). That is, \\(\\{ Q : x^TQx \\geq 0, \\forall x \\in \\mathbb{R^m}\\} = \\bigcap_x H_x\\), concluding the proof of its convexity."
  },
  {
    "objectID": "posts/linear_algebra/linalg_intro_to_linear_algebra.html#convexity",
    "href": "posts/linear_algebra/linalg_intro_to_linear_algebra.html#convexity",
    "title": "Review of Linear Algebra and Geometry for ML",
    "section": "",
    "text": "Set convexity is defined as follows:\n\nDefinition:   A set \\(C \\subseteq \\mathbb{R^d}\\) is convex if, for all points \\(x_1,x_2 \\in C\\) and any \\(\\theta \\in [0,1]\\), the point \\(\\theta x_1 + (1-\\theta) x_2\\)\n\nThat is, a set is convex if the parametrized line segment between \\(x_1\\) and \\(x_2\\), any two points in the set, is also entirely within the set. \n\n\nScaling, skewing, and rotation (i.e. linear transformations) preserve convexity, as do affine transformations (i.e. shifting). Let the matrix \\(A\\) define such a transformation, and \\(b\\) be a shift vector. Then \\(C' = \\{Ax + b : x \\in C \\}\\) is convex provided that \\(C\\) was convex.\nAn intersection of convex sets is also convex. That is, \\(C' = \\{ x : x \\in C_1 \\cap x \\in C_2 \\}\\) is convex provided that \\(C_1\\) and \\(C_2\\) were convex to begin with. The proof follows directly from the definition of intersection.\nHowever, unions of convex sets need not be convex."
  },
  {
    "objectID": "posts/linear_algebra/linalg_intro_to_linear_algebra.html#examples-of-convex-sets",
    "href": "posts/linear_algebra/linalg_intro_to_linear_algebra.html#examples-of-convex-sets",
    "title": "Review of Linear Algebra and Geometry for ML",
    "section": "",
    "text": "The following are some common convex sets we will come across in practice. To discuss sets, we should build up from points. For the purposes of the discussion that follows, A point and a vector mean the same thing.\n\n\nA convex combination of points \\(x_1, ..., x_n\\) is a point of the form \\(x = \\theta_1 x_1 + ... + \\theta_n x_n\\) where \\(\\sum_{i = 1}^{n} \\theta_i = 1\\) and \\(\\theta_i \\geq 0 \\ \\ \\forall i\\).\nLet \\(x_1,x_2,...,x_n\\) be \\(n\\) points in space. Their convex hull is the set of all points which can be written as some convex combination of them. Equivalently, by varying the \\(\\theta_i\\)’s we generate the convex hull as the set of all convex combinations of these points.\nThe convex hull can be visualized as the closed polygon formed when a rubber band is stretched around the \\(n\\) points. The convex hull of two points is the line segment joining them. That of three points is the polygon (complete with its inner region). In general, for \\(n\\) points, the concept generalizes to an \\(n\\)-dimensional polygon.\nFormally, the convex hull is the set \\(\\{ \\theta_1 x_1 + ... + \\theta_n x_n : \\theta_1 + ... + \\theta_n = 1 \\ \\ \\textrm{and} \\ \\ \\theta_i \\geq 0 \\ \\ \\forall i \\}\\)\n\n\n\n\n\n\nNote\n\n\n\n\n\nA handy interactive visualization, along with an efficient algorithm that generates a convex hull of \\(n\\) points on a 2D plane can be found in the following blog post by Joel Gibson.\n\n\n\n\n\n\nThe convex hull of a set can be similarly defined as all the convex combinations of the elements in the set. However, since the set may contain infinite elements there’s an easier, equivalent definition in terms of supersets.\nLet \\(C\\) be a non-convex set. The convex hull of \\(C\\) is the intersection of all convex supersets of \\(C\\). That is, it’s the intersection of all convex sets containing \\(C\\). The result of such an intersection will be the unique \\(^{(†)}\\) smallest convex superset of \\(C\\), its convex hull.\n\n\n(†) Proof of uniqueness: Let \\(C_1\\) and \\(C_2\\) be two convex hulls of \\(C\\). Let \\(c_1 \\in C_1\\) be a point. Since \\(c_1 \\in C_1\\), \\(c_1 \\in\\) at least one of the convex supersets \\(C^{i}\\)of \\(C\\). Hence, \\(c_1 \\in C_2\\) since \\(C_2 = \\bigcap^{i=1 \\to n}C^{i}\\). Similarly, it can be shown that any \\(c_2 \\in C_2\\) also belongs to \\(C_1\\). Hence, \\(C_1 \\subseteq C_2\\) and vice versa. This proves that \\(C_1 = C_2\\) and completes the proof of uniqueness.\nVisualizing the convex hull of a non-convex set is similar to visualizing that of \\(n\\) points — it’s simply the shape enclosed by a rubber band stretched around the non-convex set.\n\n\n\nAn affine combination of points \\(x_1,...,x_n\\) is a point of the form \\(x = \\theta_1 x_1 + ... + \\theta_n x_n\\) with \\(\\sum_{i=1}^{n}\\theta_i = 1\\) but where the \\(\\theta_i\\)’s need not be non-negative.\nFor a single point, the set of all affine combinations is the singleton set with the point itself. For two points, it’s the line that passes through them, and for three points it’s the plane. In general, it is the plane in \\(n\\)-dimensions passing through the \\(n\\) points.\n\n\n\nA linear combination of \\(n\\) vectors, on the other hand, is all vectors of the form \\(x = \\theta_1 x_1 + ... + \\theta_n x_n\\) with the \\(\\theta_i\\)’s totally unrestricted.\nThe set of all linear combinations of \\(n\\) points is called their span. Formally, it is the set \\(\\{ \\theta_1 x_1 + ... + \\theta_n x_n : \\forall \\theta_1,...,\\theta_n \\}\\).\nThe span of a single point is the line passing through it. For two vectors the span is the plane passing through them and, in general, the span of \\(n\\) points is a plane in \\((n+1)\\)-dimensions which contains these points.\n\n\nFor fixed weights \\(\\theta_i = a_i \\ \\ \\forall i\\), a hyperplane is the set of all points \\(x \\in \\mathbb{R^n}\\) whose linear combination equals a fixed constant \\(b \\in \\mathbb{R}\\).\nFormally, a hyperplane is the set \\(\\{ x : a_1 x_1 + ... a_n x_n = b\\} = \\{ x : a^T x = b\\}\\)\nThere’s a geometric interpretation of the parameters \\(a \\in \\mathbb{R^n}\\) and \\(b \\in \\mathbb{R}\\). Since the dot-product between perpendicular vectors is \\(0\\), \\(\\{ x : a^T x = 0\\}\\) is simply the set of all vectors perpendicular to \\(a\\) (whose tail, as with all vectors in linear algebra, is considered to be fixed at the origin), making \\(a\\) the normal vector to the hyperplane passing through the origin. To allow for parallel hyperplanes that are translated from the origin, the offset \\(b \\in \\mathbb{R}\\) is introduced in the generalization \\(\\{ x : a^T x = b \\}\\). This is now the set of all vectors whose dot-product with \\(a\\) is constant. These vectors are not quite perpendicular to \\(a\\), but they form a parallel hyperplane that’s been shifted from the origin by a distance of \\(\\frac{|b|}{\\|a\\|_2}\\).\nSince the sum \\(a_1 x_1 + ... a_n x_n = b\\) is fixed, the last coordinate, which we’ll call \\(x_k\\) for some \\(k \\in [1,...,n]\\), is fixed by the choice of the other \\(n-1\\) coordinates. Therefore, a hyperplane in \\(\\mathbb{R^n}\\) spans \\(n-1\\) dimensions instead of \\(n\\). \n\n\n\nA halfspace is either of the two sub-spaces a hyperplane partitions the whole space into. Since the dot-product between vectors which are roughly in the same direction is positive, and vice versa, the two halfspaces associated to a hyperplane \\(\\{ x : a^T x = b\\}\\) are \\(\\{ x : a^T x \\geq b\\}\\) and \\(\\{ x : a^T x \\leq b\\}\\).\n\n\n\n\nA conic combination of \\(x_1,...x_n\\) is a point \\(x = \\sum_{i=1}^{n} \\theta_i x_i\\) where \\(\\theta_i \\geq 0 \\ \\ \\forall i\\). Note that the absence of the restriction that \\(\\sum_{i=1}^{n} \\theta_i = 1\\) is what distinguishes a conic combination from a convex combination.\n\n\n\nRecall from Euclidean geometry that ellipses are conic sections. In general we define ellipses in \\(n\\)-dimensions as the sub-level sets of quadratic forms. That is \\(\\{ x : (x-c)^T M (x-c) \\leq 1 \\}\\) where \\(M \\succeq 0\\) defines the stretch along each principal axis, and \\(c \\in \\mathbb{R^n}\\) is the center.\nAn equivalent definition of an ellipse using the L2-norm is \\(\\{ x : \\|Ax - b\\|_2 \\leq 1 \\}\\). That is, for a given \\(A\\) and \\(b\\) in the L2-norm definition, we can find an \\(M\\) and \\(c\\) in the sub-level set definition and vice versa.\n\n\n\n\n\n\nNote\n\n\n\n\n\nMore generally, the ellipse is \\(\\{ x : (x-c)^T M (x-c) \\leq r \\}\\). However, since the scaling factor \\(r\\) is positive, it can simply be absorbed into \\(Q\\) without affecting \\(Q\\)’s positive semidefiniteness.\n\n\n\nTo quickly convince ourselves in the equivalence of these definitions, we take the simple case where \\(b = 0\\).\n\\[\n\\begin{aligned}\n  \\|Ax\\|_2 &= ((Ax)^T(Ax))^{1/2} \\\\\n  &= (x^TA^TAx)^{1/2} \\\\\n  &= (x^TU D U^Tx)^{1/2} \\\\\n  &= x^TU D^{1/2} U^Tx \\\\\n  \\end{aligned}\n\\]\nWhere the third equality is by the spectral decomposition of the real symmetric matrix \\(A^TA\\), in which \\(D = diag(\\lambda_1,...,\\lambda_n)\\) is the diagnonal matrix of eigenvalues and the columns of \\(U\\) are the corresponding eigenvectors. Taking \\(M= UD^{1/2}U^T\\), where \\(D^{1/2}\\) is simply \\(D^{1/2} = diag(\\sqrt\\lambda_1,...,\\sqrt\\lambda_n)\\), we have the equivalent sub-level set definition of the ellipse.\n\n\n\nRelated to ellipses are Euclidean balls, which are norm balls for the choice of the L2-norm. A Euclidean ball has the form \\(\\{ x : \\|x\\|_2 \\leq r \\}\\), and is clearly convex as it’s a generalizations of the sphere in \\(n\\)-dimensions.\nBut also, a Euclidean ball is the special ellipse for the choice of \\(M = rI\\), and \\(c = 0\\).\nIn general, norm balls \\(\\{ x : \\|x\\|_p \\leq r\\}\\) where \\(\\|x\\|_p = (x_1^p + ... + x_n^p)^{1/p}\\) are convex for any choice of \\(p \\geq 1\\).\n\n\n\nWhere a halfspace is a set with one linear inequality constraint, a polyhedron is a set with many, but finite, such linear inequality constraints. These constraints can be packed into a matrix \\(A \\in \\mathbb{R^{m \\times n}}\\) by vector \\(b \\in \\mathbb{R^m}\\) multiplication form, making the polyhedron into the set \\(\\{x : Ax \\leq b\\}\\).\nSince polyhedra are simply intersections of halfspaces and hyperplanes, and the latter are both convex, polyhedra are also convex sets.\n\n\n\nThe set of all PSD matrices \\(\\{ Q : x^TQx \\geq 0, \\ \\ \\forall x \\in \\mathbb{R^m}\\}\\) is convex. We can, of course, use the definition of convexity to show this. But, a more elucidative approach would be the following remark.\nNote that \\(Q \\mapsto x^TQx\\) is a linear functional that maps the space of all PSD matrices to its field of scalars. This is analogous to how \\(a \\mapsto x^Ta\\) is a linear functional so, just as \\(\\{ a : x^Ta \\geq 0 \\}\\) is a halfspace in the space of vectors, \\(H_x = \\{ Q : x^TQx \\geq 0 \\}\\) for a given choice of \\(x \\in \\mathbb{R^m}\\) is a halfspace in the space of PSD matrices. Halfspaces, as we already know, are convex and \\(\\{ Q : x^TQx \\geq 0, \\forall x \\in \\mathbb{R^m}\\}\\) is nothing but an intersection of halfspaces for each choice of \\(x\\). That is, \\(\\{ Q : x^TQx \\geq 0, \\forall x \\in \\mathbb{R^m}\\} = \\bigcap_x H_x\\), concluding the proof of its convexity."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I’m Vahram\nSoftware engineer and graduate student of computer science at UT Austin with a passion for machine learning and the applied sciences in general.\nThis blog is where I write about the subjects that interest me. It’s where I collect my notes and ideas on the web.\nI started it in late 2021 from some notes I took in Jupyter Notebooks. From there it was only a small effort to publish them via Fastpages, a blogging platform powered by Github Pages and Jekyll. In 2023, I migrated the blog from the now deprecated Fastpages to Quarto.\n\n🎓 Education\nUniversity of Texas at Austin | M.S in Computer Science (In progress)\nUniversity of California, Los Angeles | B.S. in Applied Mathematics (2020)\n\n\n💻 Experience\nCapital One | Software Engineer (Feb 2023 - Present) | Software Intern (Jun 2022 - Aug 2022)\nOmron Automation | Software Intern (Aug 2015 - Feb 2017)\n\n\n\n\n\n\n⚠️ Disclaimer\n\n\n\n\n\nAll views expressed are mine and represent me personally — not the organization(s) I am affiliated with."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vahram's Blog",
    "section": "",
    "text": "Set Up a Local Development Environment for ML\n\n\n\n\n\n\n\nPython\n\n\nConda\n\n\nQuarto\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2023\n\n\nVahram Poghosyan\n\n\n\n\n\n\n  \n\n\n\n\nConvolutional Neural Networks\n\n\n\n\n\n\n\nImage Recognition\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nVahram Poghosyan\n\n\n\n\n\n\n  \n\n\n\n\nNumPy: Quick Start Guide\n\n\n\n\n\n\n\nPython\n\n\nNumPy\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nVahram Poghosyan\n\n\n\n\n\n\n  \n\n\n\n\nReview of Linear Algebra and Geometry for ML\n\n\n\n\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2022\n\n\nVahram Poghosyan\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Optimization for ML\n\n\n\n\n\n\n\nOptimization\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2022\n\n\nVahram Poghosyan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/optimization/optimization_intro_to_optimization.html",
    "href": "posts/optimization/optimization_intro_to_optimization.html",
    "title": "Introduction to Optimization for ML",
    "section": "",
    "text": "Optimization can be viewed as the attempt to find those parameter(s), if such exist, that optimize (i.e. minimize or maximize) some objective function. The objective function can be almost anything — cost, profit, number of nodes in a wireless network, distance to a destination, a similarity measure between two images, etc. If the objective function describes cost we may wish to minimize it. If, on the other hand, it describes profit then it would suit us to maximize it.\nThe problems of minimization and maximization, summed up as optimization in one word, are the same problem up to a reflection with respect to the axis (or domain) of the parameter(s). Formally, if the objective function is \\(f: \\mathbb{R^n} \\to \\mathbb{R}\\), and it has a minimizer \\(x^* \\in \\mathbb{R^n}\\). Then, by definition of minimizer, \\(f(x^*) \\leq f(x) \\ \\ \\forall x \\in \\mathbb{R^n}\\). It follows that \\(-f(x^*) \\geq -f(x) \\ \\ \\forall x \\in \\mathbb{R^n}\\), so \\(x^*\\) is a maximizer for \\(-f\\).\n\n\nThis post is the first in a series of posts on optimization. In the series, we frame an optimization problem in this form:\n\\[\\textrm{minimize}: f(x)\\] \\[\\textrm{subject to}: x \\in \\mathcal{X}\\]\nwhere the objective function \\(f\\) is a convex function, and the constraint set \\(\\mathcal{X}\\) is a convex set.\nWe will not, however, go over the ways in which we can model a real-world problem as one of the given form in the first place. There are many creative ways of doing that, one of which you can read about in this post.\n\n\n\nFirst, let’s define the size of an optimization problem as the dimensionality of the parameter \\(x\\) added to the number of the problem constraints.\nConvex optimization problems are a class of easy optimization problems — problems whose time and/or space complexity grows slowly with respect to problem size.\nThese problems are general enough to capture many scenarios of interest, even some that do not fall strictly into the convex category, but specific enough to be solvable through generic algorithms and numerical methods."
  },
  {
    "objectID": "posts/optimization/optimization_intro_to_optimization.html#model-of-a-convex-optimization-problem",
    "href": "posts/optimization/optimization_intro_to_optimization.html#model-of-a-convex-optimization-problem",
    "title": "Introduction to Optimization for ML",
    "section": "",
    "text": "This post is the first in a series of posts on optimization. In the series, we frame an optimization problem in this form:\n\\[\\textrm{minimize}: f(x)\\] \\[\\textrm{subject to}: x \\in \\mathcal{X}\\]\nwhere the objective function \\(f\\) is a convex function, and the constraint set \\(\\mathcal{X}\\) is a convex set.\nWe will not, however, go over the ways in which we can model a real-world problem as one of the given form in the first place. There are many creative ways of doing that, one of which you can read about in this post."
  },
  {
    "objectID": "posts/optimization/optimization_intro_to_optimization.html#why-convex-optimization",
    "href": "posts/optimization/optimization_intro_to_optimization.html#why-convex-optimization",
    "title": "Introduction to Optimization for ML",
    "section": "",
    "text": "First, let’s define the size of an optimization problem as the dimensionality of the parameter \\(x\\) added to the number of the problem constraints.\nConvex optimization problems are a class of easy optimization problems — problems whose time and/or space complexity grows slowly with respect to problem size.\nThese problems are general enough to capture many scenarios of interest, even some that do not fall strictly into the convex category, but specific enough to be solvable through generic algorithms and numerical methods."
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html",
    "href": "posts/python/setting_up_our_ML_environment.html",
    "title": "Set Up a Local Development Environment for ML",
    "section": "",
    "text": "In this post we’ll be going over how to set up our local development environment for making machine learning applications and blogging about the process. This is my attempt at installing the required software packages on a Windows machine. I’ll do my best to keep things general but some of the steps will be Windows specific."
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#installing-python-on-the-system-level-optional",
    "href": "posts/python/setting_up_our_ML_environment.html#installing-python-on-the-system-level-optional",
    "title": "Setting Up Our Local Environment for Machine Learning",
    "section": "Installing Python on the System Level (Optional)",
    "text": "Installing Python on the System Level (Optional)\nFirst, we download and install the latest version of Python for our OS from the official website.\n\n\n\n\n\n\n💡 Tip\n\n\n\n\n\nMake sure to tick the “add to PATH” box during the installation so that the path of the Python executible is added to our system’s PATH environment variable. The path in question, by default, is ~\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n\n\n\n\n\n\n\n\n\n❌ Troubleshooting\n\n\n\n\n\nIf the command python is unrecognized on Windows after installation, try py. We should be able to issue the command py to invoke the Python interpreter. Running py --version should return the version number (e.g. Python 3.11.5)"
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#installing-anaconda-navigator-or-miniconda",
    "href": "posts/python/setting_up_our_ML_environment.html#installing-anaconda-navigator-or-miniconda",
    "title": "Setting Up Our Local Environment for Machine Learning",
    "section": "Installing Anaconda Navigator (or Miniconda)",
    "text": "Installing Anaconda Navigator (or Miniconda)\nNext, download and install Anaconda Navigator (or Miniconda, which installs the Conda scientific package and Python environment manager without additional software and without the GUI navigator). This installation includes tools like Jupyter Notebooks, Spyder, PyCharm, and other scientific packages and IDEs.\n\n\n\n\n\n\n📖 Note\n\n\n\n\n\nAnaconda’s built in Python distribution: Anaconda comes with its own latest Python version distribution (by default installed into path c:\\ProgramData\\anaconda3\\python.exe). The installer will prompt us to select an option which enables third-party editors, such as VSCode, to recognize this Python distribution.\n\n\n\n\n\n\n\n\n\n📖 Note\n\n\n\n\n\nDifferent Python distributions can live on the same machine: Running python --version in the Anaconda Prompt returns Python 3.11.4 as of the time of writing this, which is the version of Python that Conda installed in its base environment. Crucially, running py --version, even in the Anaconda Prompt, still returns Python 3.11.5, which is the system’s version of Python."
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#choosing-the-right-python-kernel-in-vscode",
    "href": "posts/python/setting_up_our_ML_environment.html#choosing-the-right-python-kernel-in-vscode",
    "title": "Set Up a Local Development Environment for ML",
    "section": "Choosing the Right Python Kernel in VSCode",
    "text": "Choosing the Right Python Kernel in VSCode\nIn VSCode, we can open the Command Palette and run the command Notebook: Select Notebook Kernel. At first, this will prompt us to install the Jupyter and Python VSCode extensions. Once that’s done, we can rerun the command and select the Python kernel in the desired Conda environment (by default base)."
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#initializing-conda-in-the-shell",
    "href": "posts/python/setting_up_our_ML_environment.html#initializing-conda-in-the-shell",
    "title": "Set Up a Local Development Environment for ML",
    "section": "Initializing Conda in the Shell",
    "text": "Initializing Conda in the Shell\nBefore we can use the full capabilities of Conda in the terminal, we need to initialize it by running the command:\nconda init &lt;bash|powershell|tsh|...&gt; # Depending on the shell we're using\nRestart your terminal for changes to take hold.\n\n\n\n\n\n\n❌ Troubleshooting\n\n\n\n\n\nFor Windows users, Powershell may throw the following error in trying to load the user profile: execution of scripts is disabled on this system. This is Powershell’s security measure against command hijacking, its way of enforcing control of execution and establishing identity. If this is the case, run cmd.exe as Administrator and execute command powershell Set-ExecutionPolicy RemoteSigned -Scope CurrentUser. We should now see the active environment in parentheses (e.g. base) to the left of the input in Powershell."
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#conda-commands",
    "href": "posts/python/setting_up_our_ML_environment.html#conda-commands",
    "title": "Set Up a Local Development Environment for ML",
    "section": "Conda Commands",
    "text": "Conda Commands\nSome common Conda commands are:\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\nconda env list\nShows all the Conda environments (the active environment is marked with *)\n\n\nconda list\nShows all ther packages installed in the currently active environment\n\n\nconda update --all\nUpdates all packages in the active environment (frequently resolves environment is inconsistent errors)\n\n\nconda info\nShows, among other things, the directory where the environment is stored\n\n\nconda activate &lt;myenv&gt;\nActivate environment &lt;myenv&gt;\n\n\nconda deactivate\nDeactivates the currently active environment\n\n\nconda create --name &lt;myenv&gt;\nCreate a new empty environment\n\n\nconda create --name &lt;myenv&gt; --clone base\nClone the base environment\n\n\nconda env export -f &lt;path/to/envfile.yml&gt;\nExport the package list of the active environment (e.g. conda env export -f  /Users/&lt;username&gt;/Documents/MyFiles/personal-blog.yml)\n\n\nconda compare &lt;path/to/envfile.yml&gt;\nCompare the active environment to the exported file of another environment\n\n\nconda remove --name &lt;myenv&gt; --all\nDeletes the environment\n\n\n\n\nComparing Conda Environments\nOften we need to compare the packages between two environments. Here’s the workflow to do that:\n\nActivate one of the environments using activate\nExport its package list using export as a .yml file to a destination of our choice\nActivate the second environment\nExecute the compare command, providing the path to the .yml file created in the previous step"
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#pythons-built-in-data-types",
    "href": "posts/python/setting_up_our_ML_environment.html#pythons-built-in-data-types",
    "title": "Setting Up Our Local Environment for Machine Learning",
    "section": "Python’s Built-In Data Types",
    "text": "Python’s Built-In Data Types\n\nArrays\nA 1D array, or a vector, is a collection of scalars (usually, but not necessarily, of similar data type) in a contiguous chunk of computer memory. A 2D array, or a matrix, is a collection of vectors. A 3D array (or a higher dimensional array), also referred to as a tensor, is a collection of matrices."
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#numpy-data-types",
    "href": "posts/python/setting_up_our_ML_environment.html#numpy-data-types",
    "title": "Setting Up Our Local Environment for Machine Learning",
    "section": "NumPy Data Types",
    "text": "NumPy Data Types\nNumPy exposes the ndarray type. This is a multidimensional, homogeneous array type (i.e. its elements are of the same data type) optimized for computing and indexed by a tuple. It offeres mathematical indexing (based on Boolean expressions) so that we don’t have to write inefficient loops. The terms vector, matrix, and tensor equally apply to ndarrays.\nTo import NumPy, we can type:"
  },
  {
    "objectID": "posts/neuroscience_notes/grief.html",
    "href": "posts/neuroscience_notes/grief.html",
    "title": "Overcoming Grief",
    "section": "",
    "text": "The same area of the brain lights up when we do spatial calculations, as when we do temporal ones, as when we calculate our attachment to a given person, animal, or a thing. This suggests that attachment consists of two brain processes, among possibly some others: spatial calculation of how to access a person, an animal, or a thing that is the object of our grief, and a temporal calculation of when we saw them last, or how soon we can access the object."
  },
  {
    "objectID": "posts/neuroscience_notes/grief.html#spatial-temporal-and-emotional-brain-activation",
    "href": "posts/neuroscience_notes/grief.html#spatial-temporal-and-emotional-brain-activation",
    "title": "Overcoming Grief",
    "section": "",
    "text": "The same area of the brain lights up when we do spatial calculations, as when we do temporal ones, as when we calculate our attachment to a given person, animal, or a thing. This suggests that attachment consists of two brain processes, among possibly some others: spatial calculation of how to access a person, an animal, or a thing that is the object of our grief, and a temporal calculation of when we saw them last, or how soon we can access the object."
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#installing-python---system-level-optional",
    "href": "posts/python/setting_up_our_ML_environment.html#installing-python---system-level-optional",
    "title": "Setting Up Our Local Environment for Machine Learning",
    "section": "Installing Python - System Level (Optional)",
    "text": "Installing Python - System Level (Optional)\nFirst, we download and install the latest version of Python for our OS from the official website.\n\n\n\n\n\n\n💡 Tip\n\n\n\n\n\nMake sure to tick the “add to PATH” box during the installation so that the path of the Python executible is added to our system’s PATH environment variable. The path in question, by default, is ~\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n\n\n\n\n\n\n\n\n\n❌ Troubleshooting\n\n\n\n\n\nIf the command python is unrecognized on Windows after installation, try py. We should be able to issue the command py to invoke the Python interpreter. Running py --version should return the version number (e.g. Python 3.11.5)"
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#installing-python---system-level",
    "href": "posts/python/setting_up_our_ML_environment.html#installing-python---system-level",
    "title": "Set Up a Local Development Environment for ML",
    "section": "Installing Python - System Level",
    "text": "Installing Python - System Level\nFirst, we download and install the latest version of Python for our OS from the official website.\n\n\n\n\n\n\n💡 Tip\n\n\n\n\n\nMake sure to tick the “add to PATH” box during the installation so that the path of the Python executible is added to our system’s PATH environment variable. The path in question, by default, is ~\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n\n\n\n\n\n\n\n\n\n❌ Troubleshooting\n\n\n\n\n\nIf the command python is unrecognized on Windows after installation, try py. We should be able to issue the command py to invoke the Python interpreter. Running py --version should return the version number (e.g. Python 3.11.5)"
  },
  {
    "objectID": "posts/python/setting_up_our_ML_environment.html#why-use-conda",
    "href": "posts/python/setting_up_our_ML_environment.html#why-use-conda",
    "title": "Set Up a Local Development Environment for ML",
    "section": "Why use Conda",
    "text": "Why use Conda\nWhile pip is Python’s built-in package manager and venv is its built-in virtual environment manager, we use Conda because it attempts to do more than what pip and venv try to accomplish do individually by extending support to library dependencies not written in Python.\nOccasionally, when a Conda distribution is not available, but an PyPI distribution exists, it makes sense to combine use of conda and pip. This is done by:\n\nInstalling pip within a Conda environment: conda install pip\nInstalling the required package from inside the active Conda environment: pip install &lt;package_name&gt;\n\nThis way, the packages do not go to the system-level Python’s packages directory C:\\Users\\&lt;username&gt;\\AppData\\Local\\Python\\&lt;version&gt;\\ (or Roaming instead of Local, if Python was installed only for a specific user on Windows). Instead, pip installs them in the Conda environment’s C:\\ProgramData\\anaconda3\\Lib\\site-packages (or similar) package directory. We can check each package, along with its installation destination by running pip list -v.\n\nInstalling Anaconda Navigator (or Miniconda)\nNext, download and install Anaconda Navigator (or Miniconda, which installs the Conda scientific package and Python environment manager without additional software and without the GUI navigator). This installation includes tools like Jupyter Notebooks, Spyder, PyCharm, and other scientific packages and IDEs.\n\n\n\n\n\n\n📖 Note\n\n\n\n\n\nAnaconda’s built in Python distribution: Anaconda comes with its own latest Python version distribution (by default installed into path c:\\ProgramData\\anaconda3\\python.exe). The installer will prompt us to select an option which enables third-party editors, such as VSCode, to recognize this Python distribution.\n\n\n\n\n\n\n\n\n\n📖 Note\n\n\n\n\n\nDifferent Python distributions can live on the same machine: Running python --version in the Anaconda Prompt returns Python 3.11.4 as of the time of writing this, which is the version of Python that Conda installed in its base environment. Crucially, running py --version, even in the Anaconda Prompt, still returns Python 3.11.5, which is the system’s version of Python."
  },
  {
    "objectID": "posts/python/NumPy_quick_start.html",
    "href": "posts/python/NumPy_quick_start.html",
    "title": "NumPy: Quick Start Guide",
    "section": "",
    "text": "Perhaps the most important package for scientific computing included with Conda is NumPy. Let’s get a feel for what NumPy offers.\n\n\n\n\nA 1D array, or a vector, is a collection of scalars (usually, but not necessarily, of similar data type) in a contiguous chunk of computer memory. A 2D array, or a matrix, is a collection of vectors. A 3D array (or a higher dimensional array), also referred to as a tensor, is a collection of matrices.\n\n\n\n\nNumPy exposes the ndarray type. This is a multidimensional, homogeneous array type (i.e. its elements are of the same data type) optimized for computing and indexed by a tuple. It offeres mathematical indexing (based on Boolean expressions) so that we don’t have to write inefficient loops. The terms vector, matrix, and tensor equally apply to ndarrays.\nTo import NumPy, we can type:\n\nimport numpy as np\n\n\n\n\n\n\nsequence_array = np.arange(10)\nprint(sequence_array)\n\n[0 1 2 3 4 5 6 7 8 9]\n\n\n\nzeros_array = np.zeros((3,4),dtype='int32')\nprint(zeros_array)\nprint(zeros_array.dtype)\n\n[[0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]]\nint32\n\n\n\nones_array = np.ones((3,2))\nprint(ones_array)\nprint(ones_array.dtype)\n\n[[1. 1.]\n [1. 1.]\n [1. 1.]]\nfloat64\n\n\n\n\n\nWe can verify that the object we’re working with is, indeed, and ndarray by using the built-in Python type function.\n\narray1 = np.array([1,2,3])\nprint('array1 type: ', type(array1))\n\narray1 type:  &lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\nThe shape of an ndarray is in format (x,y,...) where x corresponds to the number rows, y corresponds to the number of columns, and so on.\n\nprint('array1 shape: ', array1.shape)\n\narray1 shape:  (3,)\n\n\nHigher dimensional ndarrays take tuples of arrays as input:\n\n\nThere is a subtle difference between a 1D array and a 2D array with a single column which is worth exploring.\nAs we saw above, array1 was of shape (3,). Now let’s examine the shape of a similar ndarray instance.\n\narray2 = np.array([[1],[2],[3]])\nprint('array2 shape: ', array2.shape)\n\narray2 shape:  (3, 1)\n\n\nAs we can see, this one’s shape is (3,1).\n\n\n\n\n\n\n📖 Note\n\n\n\n\n\nThe shape (3,) means a 1D array with 3 elements, meanwhile the shape (3,1) means a 2D array with 3 rows and a single column.\n\n\n\nSometimes these differences are just superficial, or the result of data impurities. NumPy provides a method called np.squeeze which flattens the arrays by removing axes of length 1.\n\nprint(np.squeeze(array2).shape == array1.shape)\n\nTrue\n\n\n\n\n\n\narray3 = np.array([[1,2,3], \n                  [4,5,6]])\nprint('array3 shape: ', array3.shape)\n\narray3 shape:  (2, 3)\n\n\n\n\n\n\nTo get the dimension, we use ndarray.ndim.\n\nprint(array1.ndim, array2.ndim, array3.ndim)\n\n1 2 2\n\n\n\n\n\nndarrays can include numeric types (int, unsigned int, float, complex), text types (string), and null. However, as mentioned above, ndarrays can’t include more than one data type. To get the data type of the elements, we use ndarray.dtype.\n\n\n\nWe can reshape ndarrays where it makes sense. For example, we can reshape array3, of shape (2,3) into an array of shape (3,2), (6,1), or (1,6).\n\nprint(array3)\nprint(array3.shape)\narray4 = array3.reshape(3,2)\nprint(array4)\nprint(array4.shape)\n\n[[1 2 3]\n [4 5 6]]\n(2, 3)\n[[1 2]\n [3 4]\n [5 6]]\n(3, 2)\n\n\nProviding the value -1 for either row or column makes the reshape automatic across that dimension. For instance, instead of array3.reshape(3,2) we could say array3.reshape(-1,2) or array3.reshape(3,-1). This would achieve the same effect.\n\na=np.array([1,2,3])\nb=np.array([4,5,6])\nc=np.stack((a,b), axis=1)\nprint(c.shape)\n\n(3, 2)"
  },
  {
    "objectID": "posts/python/NumPy_quick_start.html#pythons-built-in-data-types",
    "href": "posts/python/NumPy_quick_start.html#pythons-built-in-data-types",
    "title": "NumPy: Quick Start Guide",
    "section": "",
    "text": "A 1D array, or a vector, is a collection of scalars (usually, but not necessarily, of similar data type) in a contiguous chunk of computer memory. A 2D array, or a matrix, is a collection of vectors. A 3D array (or a higher dimensional array), also referred to as a tensor, is a collection of matrices."
  },
  {
    "objectID": "posts/python/NumPy_quick_start.html#numpy-data-types",
    "href": "posts/python/NumPy_quick_start.html#numpy-data-types",
    "title": "NumPy: Quick Start Guide",
    "section": "",
    "text": "NumPy exposes the ndarray type. This is a multidimensional, homogeneous array type (i.e. its elements are of the same data type) optimized for computing and indexed by a tuple. It offeres mathematical indexing (based on Boolean expressions) so that we don’t have to write inefficient loops. The terms vector, matrix, and tensor equally apply to ndarrays.\nTo import NumPy, we can type:\n\nimport numpy as np\n\n\n\n\n\n\nsequence_array = np.arange(10)\nprint(sequence_array)\n\n[0 1 2 3 4 5 6 7 8 9]\n\n\n\nzeros_array = np.zeros((3,4),dtype='int32')\nprint(zeros_array)\nprint(zeros_array.dtype)\n\n[[0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]]\nint32\n\n\n\nones_array = np.ones((3,2))\nprint(ones_array)\nprint(ones_array.dtype)\n\n[[1. 1.]\n [1. 1.]\n [1. 1.]]\nfloat64\n\n\n\n\n\nWe can verify that the object we’re working with is, indeed, and ndarray by using the built-in Python type function.\n\narray1 = np.array([1,2,3])\nprint('array1 type: ', type(array1))\n\narray1 type:  &lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\nThe shape of an ndarray is in format (x,y,...) where x corresponds to the number rows, y corresponds to the number of columns, and so on.\n\nprint('array1 shape: ', array1.shape)\n\narray1 shape:  (3,)\n\n\nHigher dimensional ndarrays take tuples of arrays as input:\n\n\nThere is a subtle difference between a 1D array and a 2D array with a single column which is worth exploring.\nAs we saw above, array1 was of shape (3,). Now let’s examine the shape of a similar ndarray instance.\n\narray2 = np.array([[1],[2],[3]])\nprint('array2 shape: ', array2.shape)\n\narray2 shape:  (3, 1)\n\n\nAs we can see, this one’s shape is (3,1).\n\n\n\n\n\n\n📖 Note\n\n\n\n\n\nThe shape (3,) means a 1D array with 3 elements, meanwhile the shape (3,1) means a 2D array with 3 rows and a single column.\n\n\n\nSometimes these differences are just superficial, or the result of data impurities. NumPy provides a method called np.squeeze which flattens the arrays by removing axes of length 1.\n\nprint(np.squeeze(array2).shape == array1.shape)\n\nTrue\n\n\n\n\n\n\narray3 = np.array([[1,2,3], \n                  [4,5,6]])\nprint('array3 shape: ', array3.shape)\n\narray3 shape:  (2, 3)\n\n\n\n\n\n\nTo get the dimension, we use ndarray.ndim.\n\nprint(array1.ndim, array2.ndim, array3.ndim)\n\n1 2 2\n\n\n\n\n\nndarrays can include numeric types (int, unsigned int, float, complex), text types (string), and null. However, as mentioned above, ndarrays can’t include more than one data type. To get the data type of the elements, we use ndarray.dtype.\n\n\n\nWe can reshape ndarrays where it makes sense. For example, we can reshape array3, of shape (2,3) into an array of shape (3,2), (6,1), or (1,6).\n\nprint(array3)\nprint(array3.shape)\narray4 = array3.reshape(3,2)\nprint(array4)\nprint(array4.shape)\n\n[[1 2 3]\n [4 5 6]]\n(2, 3)\n[[1 2]\n [3 4]\n [5 6]]\n(3, 2)\n\n\nProviding the value -1 for either row or column makes the reshape automatic across that dimension. For instance, instead of array3.reshape(3,2) we could say array3.reshape(-1,2) or array3.reshape(3,-1). This would achieve the same effect.\n\na=np.array([1,2,3])\nb=np.array([4,5,6])\nc=np.stack((a,b), axis=1)\nprint(c.shape)\n\n(3, 2)"
  },
  {
    "objectID": "unpublished_posts/neuroscience_notes/grief.html",
    "href": "unpublished_posts/neuroscience_notes/grief.html",
    "title": "Overcoming Grief",
    "section": "",
    "text": "The same area of the brain lights up when we do spatial calculations, as when we do temporal ones, as when we calculate our attachment to a given person, animal, or a thing. This suggests that attachment consists of two brain processes, among possibly some others: spatial calculation of how to access a person, an animal, or a thing that is the object of our grief, and a temporal calculation of when we saw them last, or how soon we can access the object."
  },
  {
    "objectID": "unpublished_posts/neuroscience_notes/grief.html#spatial-temporal-and-emotional-brain-activation",
    "href": "unpublished_posts/neuroscience_notes/grief.html#spatial-temporal-and-emotional-brain-activation",
    "title": "Overcoming Grief",
    "section": "",
    "text": "The same area of the brain lights up when we do spatial calculations, as when we do temporal ones, as when we calculate our attachment to a given person, animal, or a thing. This suggests that attachment consists of two brain processes, among possibly some others: spatial calculation of how to access a person, an animal, or a thing that is the object of our grief, and a temporal calculation of when we saw them last, or how soon we can access the object."
  }
]