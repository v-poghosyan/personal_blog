{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c415992",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Optimization - Review of Linear Algebra and Geometry\"\n",
    "author: \"Vahram Poghosyan\"\n",
    "hide: false\n",
    "date: \"2022-01-23\"\n",
    "categories: [\"optimization\", \"linear algebra\"]\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eae137",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Optimization can be viewed as the attempt to find those parameter(s), if such exist, that optimize (i.e. minimize or maximize) some objective function. The objective function can be almost anything — cost, profit, number of nodes in a wireless network, distance to a destination, a similarity measure between two images, etc. If the objective function describes cost we may wish to minimize it. If, on the other hand, it describes profit then it would suit us to maximize it.\n",
    "\n",
    "The problems of minimization and maximization, summed up as *optimization* in one word, are the same problem up to a reflection with respect to the axis (or domain) of the parameter(s).Formally, if the objective function is $f: \\mathbb{R^n} \\to \\mathbb{R}$, and it has a minimizer $x^* \\in \\mathbb{R^n}$. Then, by definition of minimizer, $f(x^*) \\leq f(x) \\ \\ \\forall x \\in \\mathbb{R^n}$. It follows that $-f(x^*) \\geq -f(x) \\ \\ \\forall x \\in \\mathbb{R^n}$, so $x^*$ is a maximizer for $-f$.\n",
    "\n",
    "## Model of a Convex Optimization Problem\n",
    "\n",
    "This post is the first in a series of posts on optimization. In the series, we frame an optimization problem in this form:\n",
    "\n",
    "$$\\textrm{minimize}: f(x)$$\n",
    "$$\\textrm{subject to}: x \\in \\mathcal{X}$$\n",
    "\n",
    "where the *objective function* $f$ is a *convex function*, and the *constraint set* $\\mathcal{X}$ is a *convex set*.\n",
    "\n",
    "We will not, however, go over the ways in which we can model a real-world problem as one of the given form in the first place. There are many creative ways of doing that, one of which you can read about in [this post](https://v-poghosyan.github.io/blog/optimization/combinatorics/applied%20mathematics/2022/02/09/Optimization-Robust-Linear-Programs-Modelling-Discrete-Failures.html).\n",
    "\n",
    "## Why Convex Optimization?\n",
    "\n",
    "First, let's define the *size* of an optimization problem as the dimensionality of the parameter $x$ added to the number of the problem constraints.\n",
    "\n",
    "Convex optimization problems are a class of *easy* optimization problems — problems whose time and/or space complexity grows slowly with respect to problem size.\n",
    "\n",
    "These problems are general enough to capture many scenarios of interest, even some that do not fall strictly into the convex category, but specific enough to be solvable through generic algorithms and numerical methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bbacdd",
   "metadata": {},
   "source": [
    "# Review of Linear Algebra and Geometry\n",
    "\n",
    "We start our exploration of convex optimization with a refresher on convexity and the linear algebra that's commonly use in the subject.\n",
    "\n",
    "## Convexity\n",
    "\n",
    "Set convexity is defined as follows:\n",
    "\n",
    "> Definition: &nbsp; A set $C \\subseteq \\mathbb{R^d}$ is **convex** if, for all points $x_1,x_2 \\in C$ and any $\\theta \\in [0,1]$, the point $\\theta x_1 + (1-\\theta) x_2$ (i.e. the parametrized line segment between $x_1$ and $x_2$) is also in $C$.\n",
    "<br>\n",
    "\n",
    "\n",
    "### Some Operations that Preserve Convexity\n",
    "\n",
    "Scaling, skewing, and rotation (i.e. *linear transformations*) preserve convexity, as do *affine transformations* (i.e. shifting). Let the matrix $A$ define such a transformation, and $b$ be a shift vector. Then $C' = \\{Ax + b \\ |  \\ x \\in C \\}$ is convex provided that $C$ was convex.\n",
    "\n",
    "An *intersection* of convex sets is also convex. That is, $C' = \\{ x \\ | \\ x \\in C_1 \\cap x \\in C_2 \\}$ is convex provided that $C_1$ and $C_2$ were convex to begin with. The proof follows directly from the definition of intersection.\n",
    "\n",
    "However, *unions* of convex sets need not be convex.\n",
    "\n",
    "## Examples of Convex Sets\n",
    "\n",
    "The following are some common convex sets we will come across in practice.\n",
    "\n",
    "### Convex Hull of $n$ Points\n",
    "\n",
    "> Note: A *point* and a *vector* mean the same thing for the purposes of the discussion that follows.\n",
    "<br>\n",
    "\n",
    "A *convex combination* of points $x_1, ..., x_n$ is a point of the form $x = \\theta_1 x_1 + ... + \\theta_n x_n$ where $\\sum_{i = 1}^{n} \\theta_i = 1$ and $\\theta_i \\geq 0 \\ \\ \\forall i$.\n",
    "\n",
    "Let $x_1,x_2,...,x_n$ be $n$ points in space. Their *convex hull* is the set of all points which can be written as some convex combination of them. Equivalently, by varying the $\\theta_i$'s we generate the convex hull as the set of all convex combinations of these points.\n",
    "\n",
    "The convex hull can be visualized as the closed polygon formed when a rubber band is stretched around the $n$ points. The convex hull of two points is the line segment joining them. That of three points is the polygon (complete with its inner region). In general, for $n$ points, the concept generalizes to an $n$-dimensional polygon.\n",
    "\n",
    "Formally, the convex hull is the set $\\{ \\theta_1 x_1 + ... + \\theta_n x_n \\ | \\ \\theta_1 + ... + \\theta_n = 1 \\ \\ \\textrm{and} \\ \\ \\theta_i \\geq 0 \\ \\ \\forall i \\}$\n",
    "\n",
    "> Note: A handy interactive visualization, along with an efficient algorithm that generates a convex hull of $n$ points on a 2D plane can be found in the following [blog post](https://www.jgibson.id.au/articles/convex-hull/) by Joel Gibson.\n",
    "<br>\n",
    "\n",
    "### Convex Hull of a Set\n",
    "\n",
    "The convex hull of a set can be similarly defined as all the convex combinations of the elements in the set. However, since the set may contain infinite elements there's an equivalent definition in terms of supersets.\n",
    "\n",
    "Let $C$ be a non-convex set. The convex hull of $C$ is the intersection of all convex supersets of $C$. That is, it's the intersection of all convex sets containing $C$. The result of such an intersection will be the unique {% fn 1 %} smallest convex superset of $C$, its cinvex hull. \n",
    "\n",
    "Visualizing the convex hull of a non-convex set is similar to visualizing that of $n$ points — it's simply the shape enclosed by a rubber band stretched around the non-convex set.\n",
    "\n",
    "### Affine Combination of $n$ Points\n",
    "\n",
    "An *affine combination* of points $x_1,...,x_n$ is a point of the form $x = \\theta_1 x_1 + ... + \\theta_n x_n$ with $\\sum_{i=1}^{n}\\theta_i = 1$ but where the $\\theta_i$'s need not be non-negative. \n",
    "\n",
    "For a single point, the set of all affine combinations is the singleton set with the point itself. For two points, it's the *line* that passes through them, and for three points it's the *plane*. In general, it is the plane in $n$-dimensions passing through the $n$ points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f2b3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\machine-learning\\lib\\site-packages\\altair\\__init__.py\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9e6c8b024a9f4371851e35bd482d9b5b.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9e6c8b024a9f4371851e35bd482d9b5b.vega-embed details,\n",
       "  #altair-viz-9e6c8b024a9f4371851e35bd482d9b5b.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9e6c8b024a9f4371851e35bd482d9b5b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9e6c8b024a9f4371851e35bd482d9b5b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9e6c8b024a9f4371851e35bd482d9b5b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-a99664901d810a6b330d8e4930eed708\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.xval < param_1)\", \"value\": \"red\"}, \"value\": \"blue\"}, \"x\": {\"field\": \"xval\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"yval\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_1\", \"bind\": {\"input\": \"range\", \"max\": 100, \"min\": 0, \"step\": 1}, \"value\": 50}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-a99664901d810a6b330d8e4930eed708\": [{\"xval\": 0, \"yval\": 0.4967141530112327}, {\"xval\": 1, \"yval\": 0.358449851840048}, {\"xval\": 2, \"yval\": 1.0061383899407406}, {\"xval\": 3, \"yval\": 2.5291682463487657}, {\"xval\": 4, \"yval\": 2.2950148716254297}, {\"xval\": 5, \"yval\": 2.060877914676249}, {\"xval\": 6, \"yval\": 3.6400907301836405}, {\"xval\": 7, \"yval\": 4.407525459336549}, {\"xval\": 8, \"yval\": 3.938051073401597}, {\"xval\": 9, \"yval\": 4.4806111169875615}, {\"xval\": 10, \"yval\": 4.017193424175099}, {\"xval\": 11, \"yval\": 3.5514636706048424}, {\"xval\": 12, \"yval\": 3.7934259421708765}, {\"xval\": 13, \"yval\": 1.8801456975130786}, {\"xval\": 14, \"yval\": 0.15522786500004582}, {\"xval\": 15, \"yval\": -0.4070596642409269}, {\"xval\": 16, \"yval\": -1.4198907845753506}, {\"xval\": 17, \"yval\": -1.1056434519800766}, {\"xval\": 18, \"yval\": -2.0136675275012874}, {\"xval\": 19, \"yval\": -3.4259712288365787}, {\"xval\": 20, \"yval\": -1.9603224599150246}, {\"xval\": 21, \"yval\": -2.1860987604015603}, {\"xval\": 22, \"yval\": -2.1185705557136365}, {\"xval\": 23, \"yval\": -3.5433187419270933}, {\"xval\": 24, \"yval\": -4.087701466452276}, {\"xval\": 25, \"yval\": -3.9767788767424097}, {\"xval\": 26, \"yval\": -5.127772454164712}, {\"xval\": 27, \"yval\": -4.75207443581904}, {\"xval\": 28, \"yval\": -5.352713125737845}, {\"xval\": 29, \"yval\": -5.644406875531121}, {\"xval\": 30, \"yval\": -6.2461134877605184}, {\"xval\": 31, \"yval\": -4.3938353032515804}, {\"xval\": 32, \"yval\": -4.407332527989515}, {\"xval\": 33, \"yval\": -5.4650434569454145}, {\"xval\": 34, \"yval\": -4.642498544842225}, {\"xval\": 35, \"yval\": -5.863342194813248}, {\"xval\": 36, \"yval\": -5.654478599808492}, {\"xval\": 37, \"yval\": -7.614148723688268}, {\"xval\": 38, \"yval\": -8.942334772586698}, {\"xval\": 39, \"yval\": -8.745473536717574}, {\"xval\": 40, \"yval\": -8.007006956722163}, {\"xval\": 41, \"yval\": -7.835638675532193}, {\"xval\": 42, \"yval\": -7.951286957920433}, {\"xval\": 43, \"yval\": -8.252390653509723}, {\"xval\": 44, \"yval\": -9.73091264387715}, {\"xval\": 45, \"yval\": -10.450756852271859}, {\"xval\": 46, \"yval\": -10.911395623231646}, {\"xval\": 47, \"yval\": -9.854273397012731}, {\"xval\": 48, \"yval\": -9.51065510744427}, {\"xval\": 49, \"yval\": -11.273695262807005}, {\"xval\": 50, \"yval\": -10.94961129341221}, {\"xval\": 51, \"yval\": -11.334693573828526}, {\"xval\": 52, \"yval\": -12.011615574134485}, {\"xval\": 53, \"yval\": -11.399939285293616}, {\"xval\": 54, \"yval\": -10.368939762797666}, {\"xval\": 55, \"yval\": -9.437659643681467}, {\"xval\": 56, \"yval\": -10.276877166904105}, {\"xval\": 57, \"yval\": -10.58608954275532}, {\"xval\": 58, \"yval\": -10.254826111351756}, {\"xval\": 59, \"yval\": -9.279280984229397}, {\"xval\": 60, \"yval\": -9.758455222074687}, {\"xval\": 61, \"yval\": -9.944114198738504}, {\"xval\": 62, \"yval\": -11.050449172744532}, {\"xval\": 63, \"yval\": -12.246655796825202}, {\"xval\": 64, \"yval\": -11.434129974431004}, {\"xval\": 65, \"yval\": -10.07788994586018}, {\"xval\": 66, \"yval\": -10.149900067440514}, {\"xval\": 67, \"yval\": -9.14636716954849}, {\"xval\": 68, \"yval\": -8.784731144500856}, {\"xval\": 69, \"yval\": -9.42985089910598}, {\"xval\": 70, \"yval\": -9.068455293597568}, {\"xval\": 71, \"yval\": -7.5304187271315985}, {\"xval\": 72, \"yval\": -7.56624476624155}, {\"xval\": 73, \"yval\": -6.001601110427544}, {\"xval\": 74, \"yval\": -8.621346214517288}, {\"xval\": 75, \"yval\": -7.799443710142064}, {\"xval\": 76, \"yval\": -7.712396641903893}, {\"xval\": 77, \"yval\": -8.011403992369761}, {\"xval\": 78, \"yval\": -7.919643215834259}, {\"xval\": 79, \"yval\": -9.907212130435152}, {\"xval\": 80, \"yval\": -10.126884018272664}, {\"xval\": 81, \"yval\": -9.769771446760917}, {\"xval\": 82, \"yval\": -8.2918774020194}, {\"xval\": 83, \"yval\": -8.810147620293048}, {\"xval\": 84, \"yval\": -9.618641223186236}, {\"xval\": 85, \"yval\": -10.120398266770772}, {\"xval\": 86, \"yval\": -9.204996149068698}, {\"xval\": 87, \"yval\": -8.876245039409014}, {\"xval\": 88, \"yval\": -9.406005243176052}, {\"xval\": 89, \"yval\": -8.892737810062696}, {\"xval\": 90, \"yval\": -8.795660260714657}, {\"xval\": 91, \"yval\": -7.827015270181768}, {\"xval\": 92, \"yval\": -8.529068364059121}, {\"xval\": 93, \"yval\": -8.85673051065689}, {\"xval\": 94, \"yval\": -9.248838663789048}, {\"xval\": 95, \"yval\": -10.712353611921166}, {\"xval\": 96, \"yval\": -10.41623333485659}, {\"xval\": 97, \"yval\": -10.1551780626767}, {\"xval\": 98, \"yval\": -10.15006460603424}, {\"xval\": 99, \"yval\": -10.384651739409387}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rand = np.random.RandomState(42)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'xval': range(100),\n",
    "    'yval': rand.randn(100).cumsum()\n",
    "})\n",
    "\n",
    "print(altair.__file__)\n",
    "\n",
    "\n",
    "slider = alt.binding_range(min=0, max=100, step=1)\n",
    "cutoff = alt.param(bind=slider, value=50)\n",
    "\n",
    "\n",
    "\n",
    "alt.Chart(df).mark_point().encode(\n",
    "    x='xval',\n",
    "    y='yval',\n",
    "    color=alt.condition(\n",
    "        alt.datum.xval < cutoff,\n",
    "        alt.value('red'), alt.value('blue')\n",
    "    )\n",
    ").add_params(\n",
    "    cutoff\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0e79b",
   "metadata": {},
   "source": [
    "### Linear Combinations - Hyperplanes and Halfspaces\n",
    "\n",
    "A *linear combination* of $n$ vectors, on the other hand, is all vectors of the form $x = \\theta_1 x_1 + ... + \\theta_n x_n$ with the $\\theta_i$'s totally unrestricted. \n",
    "\n",
    "The set of all linear combinations of $n$ points is called their *span*. Formally, it is the set $\\{ \\theta_1 x_1 + ... + \\theta_n x_n \\ \\ | \\ \\ \\forall \\theta_1,...,\\theta_n \\}$.\n",
    "\n",
    "The span of a single point is the line passing through it. For two vectors the span is the plane passing through them and, in general, the span of $n$ points is a plane in $(n+1)$-dimensions which contains these points.\n",
    "\n",
    "\n",
    "#### Hyperplanes\n",
    "\n",
    "For fixed weights $\\theta_i = a_i \\ \\ \\forall i$, a *hyperplane* is the set of all points $x \\in \\mathbb{R^n}$ whose linear combination equals a fixed constant $b \\in \\mathbb{R}$.\n",
    "\n",
    "Formally, a hyperplane is the set $\\{ x \\ \\ | \\ \\ a_1 x_1 + ... a_n x_n = b\\} = \\{ x \\ \\ | \\ \\ a^T x = b\\}$ \n",
    "\n",
    "There's a geometric interpretation of the parameters $a \\in \\mathbb{R^n}$ and $b \\in \\mathbb{R}$. Since the dot-product between perpendicular vectors is $0$, $\\{ x \\ \\ | \\ \\  a^T x = 0\\}$ is simply the set of all vectors perpendicular to $a$ (whose tail, as with all vectors in linear algebra, is considered to be fixed at the origin), making $a$ the *normal vector* to the hyperplane passing through the origin. To allow for parallel hyperplanes that are translated from the origin, the *offset* $b \\in \\mathbb{R}$ is introduced in the generalization $\\{ x \\ \\ | \\ \\ a^T x = b \\}$. This is now the set of all vectors whose dot-product with $a$ is constant. These vectors are not quite perpendicular to $a$, but they form a parallel hyperplane that's been shifted from the origin by a distance of $\\frac{|b|}{\\|a\\|_2}$.\n",
    "\n",
    "Since the sum $a_1 x_1 + ... a_n x_n = b$ is fixed, the last coordinate, which we'll call $x_k$ for some $k \\in [1,...,n]$, is fixed by the choice of the other $n-1$ coordinates. Therefore, a hyperplane  in $\\mathbb{R^n}$ spans $n-1$ dimensions instead of $n$.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ebfb8",
   "metadata": {},
   "source": [
    "#### Halfspaces\n",
    "\n",
    "A *halfspace* is either of the two sub-spaces a hyperplane partitions the whole space into. Since the dot-product between vectors which are roughly in the same direction is positive, and vice versa, the two halfspaces associated to a hyperplane $\\{ x \\ \\ | \\ \\ a^T x = b\\}$ are $\\{ x \\ \\ | \\ \\ a^T x \\geq b\\}$ and $\\{ x \\ \\ | \\ \\ a^T x \\leq b\\} $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427fa71",
   "metadata": {},
   "source": [
    "### Conic Combinations of $n$ Points\n",
    "\n",
    "A *conic combination* of $x_1,...x_n$ is a point $x = \\sum_{i=1}^{n} \\theta_i x_i$ where $\\theta_i \\geq 0 \\ \\ \\forall i$. Note that the absence of the restriction that $\\sum_{i=1}^{n} \\theta_i = 1$ is what distinguishes a conic combination from a convex combination. \n",
    "\n",
    "**A visual example:**\n",
    "\n",
    "![](my_icons/conic-combination.png \"The conic combination of vectors (0,1) and (1,1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc519372",
   "metadata": {},
   "source": [
    "### Ellipses\n",
    "\n",
    "Recall from Euclidean geometry that ellipses are conic sections. In general we define ellipses in $n$-dimensions as the [sub-level sets](https://en.wikipedia.org/wiki/Level_set) of [quadratic forms](https://en.wikipedia.org/wiki/Quadratic_form). That is $\\{ x \\ \\ | \\ \\ (x-c)^T M (x-c) \\leq 1 \\}$ where $M \\succeq 0$ defines the stretch along each principal axis, and $c \\in \\mathbb{R^n}$ is the center. \n",
    "\n",
    "An equivalent definition of an ellipse using the L2-norm is $\\{ x  \\ \\ |  \\ \\ \\|Ax - b\\|_2 \\leq 1 \\}$. That is, for a given $A$ and $b$ in the L2-norm definition, we can find an $M$ and $c$ in the sub-level set definition and vice versa.  \n",
    "\n",
    "> Note: More generally, the ellipse is $\\{ x \\ \\ | \\ \\ (x-c)^T M (x-c) \\leq r \\}$. However, since the scaling factor $r$ is positive, it can simply be absorbed into $Q$ without affecting $Q$'s positive semidefiniteness.\n",
    "<br>\n",
    "\n",
    "To quickly convince ourselves in the equivalence of these definitions, we take the simple case where $b = 0$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  \\|Ax\\|_2 &= ((Ax)^T(Ax))^{1/2} \\\\\n",
    "  &= (x^TA^TAx)^{1/2} \\\\\n",
    "  &= (x^TU D U^Tx)^{1/2} \\\\\n",
    "  &= x^TU D^{1/2} U^Tx \\\\\n",
    "  \\end{aligned}\n",
    "$$\n",
    "\n",
    "Where the third equality is by the [spectral decomposition](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix#Real_symmetric_matrices) of the real symmetric matrix $A^TA$, in which $D = diag(\\lambda_1,...,\\lambda_n)$ is the diagnonal matrix of eigenvalues and the columns of $U$ are the corresponding eigenvectors. Taking $M= UD^{1/2}U^T$, where $D^{1/2}$ is simply $D^{1/2} = diag(\\sqrt\\lambda_1,...,\\sqrt\\lambda_n)$, we have the equivalent sub-level set definition of the ellipse. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dd7c1",
   "metadata": {},
   "source": [
    "### Norm Balls\n",
    "\n",
    "Related to ellipses are *Euclidean balls*, which are *norm balls* for the choice of the L2-norm. A Euclidean ball has the form $\\{ x \\ \\ | \\ \\ \\|x\\|_2 \\leq r \\}$, and is clearly convex as it's a generalizations of the sphere in $n$-dimensions. \n",
    "\n",
    "But also, a Euclidean ball is the special ellipse for the choice of $M = rI$, and $c = 0$. \n",
    "\n",
    "In general, norm balls $\\{ x \\ \\ | \\ \\ \\|x\\|_p \\leq r\\}$ where $\\|x\\|_p = (x_1^p + ... + x_n^p)^{1/p}$ are convex for any choice of $p \\geq 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d8b6d",
   "metadata": {},
   "source": [
    "### Polyhedra\n",
    "\n",
    "Where a halfspace is a set with one linear inequality constraint, a *polyhedron* is a set with many, but finite, such linear inequality constraints. These constraints can be packed into a matrix $A \\in \\mathbb{R^{m \\times n}}$ by vector $b \\in \\mathbb{R^m}$ multiplication form, making the polyhedron into the set $\\{x \\ \\ | \\ \\ Ax \\leq b\\}$.\n",
    "\n",
    "Since polyhedra are simply intersections of halfspaces and hyperplanes, and the latter are both convex, polyhedra are also convex sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0729f0f5",
   "metadata": {},
   "source": [
    "### The Set of All Positive Semidefinite Matrices\n",
    "\n",
    "The set of all PSD matrices $\\{ Q \\ \\ | \\ \\ x^TQx \\geq 0 \\ \\ \\forall x \\in \\mathbb{R^m}\\}$ is convex. We can, of course, use the definition of convexity to show this. But, a more elucidative approach would be the following remark. \n",
    "\n",
    "Note that $Q \\mapsto x^TQx$ is a [linear functional](https://en.wikipedia.org/wiki/Linear_form) that maps the space of all PSD matrices to its field of scalars. This is analogous to how $a \\mapsto x^Ta$ is a linear functional so, just as $\\{ a \\ \\ | \\ \\ x^Ta \\geq 0 \\}$ is a halfspace in the space of vectors, $H_x = \\{ Q \\ \\ | \\ \\ x^TQx \\geq 0 \\}$ for a given choice of $x \\in \\mathbb{R^m}$ is a halfspace in the space of PSD matrices. Halfspaces, as we already know, are convex and $\\{ Q \\ \\ | \\ \\ x^TQx \\geq 0 \\ \\ \\forall x \\in \\mathbb{R^m}\\}$ is nothing but an intersection of halfspaces for each choice of $x$. That is, $\\{ Q \\ \\ | \\ \\ x^TQx \\geq 0 \\ \\ \\forall x \\in \\mathbb{R^m}\\} = \\bigcap_x H_x$, concluding the proof of its convexity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b7d84",
   "metadata": {},
   "source": [
    "{{ '**Proof of uniqueness of the minimal, convex superset:** \n",
    "Suppose $C_1$ and $C_2$ are both minimal, convex supersets of $C$. Any convex set $D$ that contains $C$ must clearly contain the minimal, convex superset. Hence, $C_1 \\subseteq C_2$ and $C_2 \\subseteq C_1$, which implies $C_1 = C_2$.' | fndetail: 1 }}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7953a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
